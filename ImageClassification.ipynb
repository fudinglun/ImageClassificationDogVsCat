{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Scale(130),\n",
    "    transforms.RandomCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindir = \"/Users/Dylan/Desktop/dogcat/train/\"\n",
    "validdir = \"/Users/Dylan/Desktop/dogcat/smallvalidate/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = datasets.ImageFolder(traindir, transform)\n",
    "valid = datasets.ImageFolder(validdir, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertImage(data):\n",
    "    return [data[0][:1], data[1]]\n",
    "\n",
    "valid = [convertImage(i) for i in valid]\n",
    "train = [convertImage(i) for i in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " ( 0 ,.,.) = \n",
       "   0.5608  0.5765  0.5765  ...   0.7725  0.7725  0.7804\n",
       "   0.5608  0.5765  0.5765  ...   0.7725  0.7725  0.7804\n",
       "   0.5765  0.5922  0.5922  ...   0.7725  0.7725  0.7804\n",
       "            ...             ⋱             ...          \n",
       "  -0.1922 -0.2784 -0.3569  ...  -0.4824 -0.5373 -0.6000\n",
       "  -0.1765 -0.2627 -0.3412  ...  -0.6784 -0.7098 -0.7255\n",
       "  -0.1765 -0.2471 -0.3255  ...  -0.8588 -0.8588 -0.8510\n",
       " [torch.FloatTensor of size 1x128x128], 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 50\n",
    "BATCH_SIZE = 50\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_y = [i[1] for i in valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_y = torch.from_numpy(np.array(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_x = [i[0] for i in valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_x = torch.stack(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 1, 128, 128])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_x = Variable(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 3 * 3, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 2),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN (\n",
      "  (features): Sequential (\n",
      "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU (inplace)\n",
      "    (2): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU (inplace)\n",
      "    (5): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU (inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU (inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU (inplace)\n",
      "    (12): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (classifier): Sequential (\n",
      "    (0): Dropout (p = 0.5)\n",
      "    (1): Linear (2304 -> 4096)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): Dropout (p = 0.5)\n",
      "    (4): Linear (4096 -> 4096)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Linear (4096 -> 2)\n",
      "    (7): Softmax ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 0 | train loss: 0.6927 | test accuracy: 0.50\n",
      "Epoch:  0 20 | train loss: 0.6944 | test accuracy: 0.50\n",
      "Epoch:  0 40 | train loss: 0.6953 | test accuracy: 0.50\n",
      "Epoch:  0 60 | train loss: 0.6918 | test accuracy: 0.57\n",
      "Epoch:  0 80 | train loss: 0.6953 | test accuracy: 0.50\n",
      "Epoch:  0 100 | train loss: 0.6821 | test accuracy: 0.62\n",
      "Epoch:  0 120 | train loss: 0.6739 | test accuracy: 0.62\n",
      "Epoch:  0 140 | train loss: 0.6346 | test accuracy: 0.65\n",
      "Epoch:  0 160 | train loss: 0.6361 | test accuracy: 0.50\n",
      "Epoch:  0 180 | train loss: 0.6869 | test accuracy: 0.65\n",
      "Epoch:  0 200 | train loss: 0.6088 | test accuracy: 0.53\n",
      "Epoch:  0 220 | train loss: 0.6173 | test accuracy: 0.57\n",
      "Epoch:  0 240 | train loss: 0.6293 | test accuracy: 0.57\n",
      "Epoch:  0 260 | train loss: 0.6061 | test accuracy: 0.55\n",
      "Epoch:  0 280 | train loss: 0.6645 | test accuracy: 0.55\n",
      "Epoch:  0 300 | train loss: 0.5532 | test accuracy: 0.60\n",
      "Epoch:  0 320 | train loss: 0.6224 | test accuracy: 0.62\n",
      "Epoch:  0 340 | train loss: 0.5677 | test accuracy: 0.62\n",
      "Epoch:  0 360 | train loss: 0.6065 | test accuracy: 0.53\n",
      "Epoch:  0 380 | train loss: 0.5919 | test accuracy: 0.57\n",
      "Epoch:  0 400 | train loss: 0.6568 | test accuracy: 0.65\n",
      "Epoch:  0 420 | train loss: 0.6429 | test accuracy: 0.57\n",
      "Epoch:  1 0 | train loss: 0.5472 | test accuracy: 0.68\n",
      "Epoch:  1 20 | train loss: 0.6016 | test accuracy: 0.57\n",
      "Epoch:  1 40 | train loss: 0.5541 | test accuracy: 0.62\n",
      "Epoch:  1 60 | train loss: 0.6476 | test accuracy: 0.57\n",
      "Epoch:  1 80 | train loss: 0.6832 | test accuracy: 0.65\n",
      "Epoch:  1 100 | train loss: 0.6470 | test accuracy: 0.60\n",
      "Epoch:  1 120 | train loss: 0.5491 | test accuracy: 0.70\n",
      "Epoch:  1 140 | train loss: 0.6613 | test accuracy: 0.68\n",
      "Epoch:  1 160 | train loss: 0.6106 | test accuracy: 0.62\n",
      "Epoch:  1 180 | train loss: 0.7591 | test accuracy: 0.68\n",
      "Epoch:  1 200 | train loss: 0.7336 | test accuracy: 0.65\n",
      "Epoch:  1 220 | train loss: 0.5728 | test accuracy: 0.65\n",
      "Epoch:  1 240 | train loss: 0.4732 | test accuracy: 0.65\n",
      "Epoch:  1 260 | train loss: 0.6946 | test accuracy: 0.68\n",
      "Epoch:  1 280 | train loss: 0.5994 | test accuracy: 0.65\n",
      "Epoch:  1 300 | train loss: 0.4418 | test accuracy: 0.65\n",
      "Epoch:  1 320 | train loss: 0.5397 | test accuracy: 0.68\n",
      "Epoch:  1 340 | train loss: 0.5373 | test accuracy: 0.65\n",
      "Epoch:  1 360 | train loss: 0.4897 | test accuracy: 0.68\n",
      "Epoch:  1 380 | train loss: 0.5859 | test accuracy: 0.62\n",
      "Epoch:  1 400 | train loss: 0.5572 | test accuracy: 0.62\n",
      "Epoch:  1 420 | train loss: 0.6253 | test accuracy: 0.62\n",
      "Epoch:  2 0 | train loss: 0.5028 | test accuracy: 0.68\n",
      "Epoch:  2 20 | train loss: 0.4223 | test accuracy: 0.68\n",
      "Epoch:  2 40 | train loss: 0.4860 | test accuracy: 0.62\n",
      "Epoch:  2 60 | train loss: 0.5957 | test accuracy: 0.78\n",
      "Epoch:  2 80 | train loss: 0.5057 | test accuracy: 0.70\n",
      "Epoch:  2 100 | train loss: 0.5205 | test accuracy: 0.70\n",
      "Epoch:  2 120 | train loss: 0.4696 | test accuracy: 0.68\n",
      "Epoch:  2 140 | train loss: 0.5259 | test accuracy: 0.70\n",
      "Epoch:  2 160 | train loss: 0.5627 | test accuracy: 0.72\n",
      "Epoch:  2 180 | train loss: 0.5498 | test accuracy: 0.68\n",
      "Epoch:  2 200 | train loss: 0.4924 | test accuracy: 0.70\n",
      "Epoch:  2 220 | train loss: 0.5266 | test accuracy: 0.78\n",
      "Epoch:  2 240 | train loss: 0.5299 | test accuracy: 0.65\n",
      "Epoch:  2 260 | train loss: 0.4692 | test accuracy: 0.70\n",
      "Epoch:  2 280 | train loss: 0.5660 | test accuracy: 0.72\n",
      "Epoch:  2 300 | train loss: 0.5907 | test accuracy: 0.72\n",
      "Epoch:  2 320 | train loss: 0.5181 | test accuracy: 0.70\n",
      "Epoch:  2 340 | train loss: 0.4955 | test accuracy: 0.70\n",
      "Epoch:  2 360 | train loss: 0.5923 | test accuracy: 0.70\n",
      "Epoch:  2 380 | train loss: 0.5282 | test accuracy: 0.80\n",
      "Epoch:  2 400 | train loss: 0.5553 | test accuracy: 0.72\n",
      "Epoch:  2 420 | train loss: 0.5170 | test accuracy: 0.72\n",
      "Epoch:  3 0 | train loss: 0.4910 | test accuracy: 0.70\n",
      "Epoch:  3 20 | train loss: 0.5149 | test accuracy: 0.70\n",
      "Epoch:  3 40 | train loss: 0.5871 | test accuracy: 0.75\n",
      "Epoch:  3 60 | train loss: 0.4469 | test accuracy: 0.80\n",
      "Epoch:  3 80 | train loss: 0.5386 | test accuracy: 0.72\n",
      "Epoch:  3 100 | train loss: 0.4471 | test accuracy: 0.80\n",
      "Epoch:  3 120 | train loss: 0.5544 | test accuracy: 0.72\n",
      "Epoch:  3 140 | train loss: 0.4873 | test accuracy: 0.78\n",
      "Epoch:  3 160 | train loss: 0.4984 | test accuracy: 0.72\n",
      "Epoch:  3 180 | train loss: 0.4394 | test accuracy: 0.75\n",
      "Epoch:  3 200 | train loss: 0.5558 | test accuracy: 0.78\n",
      "Epoch:  3 220 | train loss: 0.5559 | test accuracy: 0.75\n",
      "Epoch:  3 240 | train loss: 0.4761 | test accuracy: 0.75\n",
      "Epoch:  3 260 | train loss: 0.5249 | test accuracy: 0.68\n",
      "Epoch:  3 280 | train loss: 0.6199 | test accuracy: 0.75\n",
      "Epoch:  3 300 | train loss: 0.5208 | test accuracy: 0.70\n",
      "Epoch:  3 320 | train loss: 0.4613 | test accuracy: 0.72\n",
      "Epoch:  3 340 | train loss: 0.5409 | test accuracy: 0.72\n",
      "Epoch:  3 360 | train loss: 0.4845 | test accuracy: 0.65\n",
      "Epoch:  3 380 | train loss: 0.5244 | test accuracy: 0.78\n",
      "Epoch:  3 400 | train loss: 0.4807 | test accuracy: 0.75\n",
      "Epoch:  3 420 | train loss: 0.4775 | test accuracy: 0.75\n",
      "Epoch:  4 0 | train loss: 0.5390 | test accuracy: 0.75\n",
      "Epoch:  4 20 | train loss: 0.5153 | test accuracy: 0.80\n",
      "Epoch:  4 40 | train loss: 0.4784 | test accuracy: 0.65\n",
      "Epoch:  4 60 | train loss: 0.5045 | test accuracy: 0.75\n",
      "Epoch:  4 80 | train loss: 0.5191 | test accuracy: 0.75\n",
      "Epoch:  4 100 | train loss: 0.4202 | test accuracy: 0.72\n",
      "Epoch:  4 120 | train loss: 0.5110 | test accuracy: 0.72\n",
      "Epoch:  4 140 | train loss: 0.4421 | test accuracy: 0.75\n",
      "Epoch:  4 160 | train loss: 0.5441 | test accuracy: 0.75\n",
      "Epoch:  4 180 | train loss: 0.4706 | test accuracy: 0.75\n",
      "Epoch:  4 200 | train loss: 0.5249 | test accuracy: 0.80\n",
      "Epoch:  4 220 | train loss: 0.4357 | test accuracy: 0.68\n",
      "Epoch:  4 240 | train loss: 0.6203 | test accuracy: 0.68\n",
      "Epoch:  4 260 | train loss: 0.5228 | test accuracy: 0.68\n",
      "Epoch:  4 280 | train loss: 0.4615 | test accuracy: 0.80\n",
      "Epoch:  4 300 | train loss: 0.5072 | test accuracy: 0.88\n",
      "Epoch:  4 320 | train loss: 0.4376 | test accuracy: 0.82\n",
      "Epoch:  4 340 | train loss: 0.5000 | test accuracy: 0.75\n",
      "Epoch:  4 360 | train loss: 0.4912 | test accuracy: 0.72\n",
      "Epoch:  4 380 | train loss: 0.4744 | test accuracy: 0.78\n",
      "Epoch:  4 400 | train loss: 0.4879 | test accuracy: 0.82\n",
      "Epoch:  4 420 | train loss: 0.4742 | test accuracy: 0.80\n",
      "Epoch:  5 0 | train loss: 0.4616 | test accuracy: 0.82\n",
      "Epoch:  5 20 | train loss: 0.4526 | test accuracy: 0.78\n",
      "Epoch:  5 40 | train loss: 0.5381 | test accuracy: 0.78\n",
      "Epoch:  5 60 | train loss: 0.4499 | test accuracy: 0.72\n",
      "Epoch:  5 80 | train loss: 0.5022 | test accuracy: 0.72\n",
      "Epoch:  5 100 | train loss: 0.5799 | test accuracy: 0.72\n",
      "Epoch:  5 120 | train loss: 0.4137 | test accuracy: 0.72\n",
      "Epoch:  5 140 | train loss: 0.5228 | test accuracy: 0.78\n",
      "Epoch:  5 160 | train loss: 0.4381 | test accuracy: 0.82\n",
      "Epoch:  5 180 | train loss: 0.5854 | test accuracy: 0.78\n",
      "Epoch:  5 200 | train loss: 0.6018 | test accuracy: 0.78\n",
      "Epoch:  5 220 | train loss: 0.4727 | test accuracy: 0.80\n",
      "Epoch:  5 240 | train loss: 0.5406 | test accuracy: 0.68\n",
      "Epoch:  5 260 | train loss: 0.4987 | test accuracy: 0.75\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f4b401fa9187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# clear gradients for this training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# backpropagation, compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtest_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/3point6/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        b_x = Variable(x)\n",
    "        b_y = Variable(y)\n",
    "        output = cnn(b_x)[0]               # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()  \n",
    "        if step % 20 == 0:\n",
    "            test_output, last_layer = cnn(validation_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = sum(pred_y == valid_y) / float(valid_y.size(0))\n",
    "            print('Epoch: ', epoch, step,'| train loss: %.4f' % loss.data[0], '| test accuracy: %.2f' % accuracy)\n",
    "#         print(b_y)\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = train[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = torch.stack([t1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = cnn(Variable(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.5000  0.5000\n",
       "[torch.FloatTensor of size 1x2]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 ,.,.) = \n",
       "  0.6078  0.6157  0.6235  ...   0.7725  0.7647  0.7490\n",
       "  0.6078  0.6157  0.6157  ...   0.7725  0.7647  0.7569\n",
       "  0.6078  0.6157  0.6078  ...   0.7804  0.7725  0.7725\n",
       "           ...             ⋱             ...          \n",
       " -0.6471 -0.6235 -0.6000  ...  -0.9765 -0.9765 -0.9686\n",
       " -0.6471 -0.6235 -0.6235  ...  -0.9765 -0.9765 -0.9843\n",
       " -0.6706 -0.6549 -0.6471  ...  -0.9843 -0.9843 -0.9922\n",
       "[torch.FloatTensor of size 1x128x128]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.6)",
   "language": "python",
   "name": "3point6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
